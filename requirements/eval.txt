# Evaluation-only dependencies (kept separate from training deps)
# Install: pip install -r requirements/eval.txt

# EleutherAI lm-evaluation-harness (standard benchmark runner)
lm-eval==0.4.7

# Some tasks rely on these; keep lightweight
sacrebleu>=2.4.0
rouge-score>=0.1.2
